# RMIT Course Advisor Project - Technical Documentation

## Project Purpose
The RMIT Course Advisor is an AI-powered chatbot designed to assist RMIT Cyber Security students with course planning and enquiries. It combines data extraction, multi-format data handling, and AI-driven conversational assistance in a Streamlit web application.

---

## app.py - Main Application

### Key Concepts and Methods

- **Streamlit:** Used to build the interactive web UI, including sidebar, file uploaders, chat interface, buttons, and login form with session tracking.
- **User Login and Session Tracking:** Implements a login form in the sidebar where users enter their RMIT username and password. Login state and credentials are securely stored in Streamlit's `session_state`. Logout functionality clears the session.
- **AWS Cognito Authentication (`get_credentials`):** Authenticates users securely using AWS Cognito Identity Provider and Identity Pool to obtain temporary AWS credentials based on user login.
- **AWS Bedrock AI Model Integration (`ask_claude`):** Sends user prompts to the Claude AI model hosted on AWS Bedrock for generating intelligent responses, using credentials from the logged-in user.
- **Text Extraction from Images (`extract_text_from_image`):** Uses `pytesseract` library to perform Optical Character Recognition (OCR) on uploaded images to extract text.
- **PDF Text Extraction (`extract_text_from_pdf` and `convert_pdf_to_json`):** Uses `pdfplumber` to extract text from PDF files, with an option to convert and download the extracted content as JSON.
- **CSV Data Loading (`load_csv_data`):** Parses uploaded CSV files using Python's built-in `csv` module.
- **SQLite Database Loading (`load_db_data`):** Reads course data from an uploaded or default SQLite database using the `sqlite3` module.
- **Chat History Management:** Saves and loads chat history to/from a JSON file, allowing users to download or clear past conversations.
- **Typing Animation (`type_text`):** Simulates typing effect for AI responses in the chat interface.

---

## data_extraction.py - Data Extraction Script

### Key Concepts and Methods

- **Sitemap Downloading (`download_sitemap`):** Uses `requests` library to fetch the RMIT sitemap XML.
- **Sitemap Parsing (`parse_sitemap`):** Parses the XML sitemap using Python's built-in `xml.etree.ElementTree` to extract URLs.
- **Web Page Downloading (`download_page`):** Downloads individual course pages using `requests`.
- **HTML Parsing and Data Extraction (`parse_page`):** Uses `BeautifulSoup` from `bs4` to parse HTML content and extract course metadata such as course code, title, semester, credits, campus, school, career, description, topics, prerequisites, and course type.
- **Data Storage (`save_data_to_db`):** Saves the extracted course data into a local SQLite database (`extracted_data.db`) using the `sqlite3` module.
- **Filtering URLs:** Filters URLs from the sitemap to include only relevant course pages based on keywords.

---

## Libraries and Tools Used

- **Streamlit:** Framework for building interactive web applications in Python.
- **pytesseract:** Python wrapper for Google's Tesseract-OCR Engine, used for extracting text from images.
- **pdfplumber:** Library for extracting text and metadata from PDF files.
- **boto3:** AWS SDK for Python, used here for interacting with AWS Cognito and Bedrock services.
- **requests:** HTTP library for downloading web content.
- **BeautifulSoup (bs4):** HTML/XML parser for extracting data from web pages.
- **sqlite3:** Python's built-in library for interacting with SQLite databases.
- **dotenv:** Loads environment variables from a `.env` file for secure credential management.
- **json, csv, io, os, time:** Standard Python libraries for data handling, file operations, and timing.

---

## Usage Overview

- Run the Streamlit app (`app.py`) to launch the chatbot UI.
- Upload course data in JSON, CSV, PDF, SQLite DB, or image formats.
- Use the chat interface to ask questions about courses; responses are generated by the AI model.
- Convert PDFs to JSON within the UI for easier data integration.
- Use `data_extraction.py` to scrape and update course data from the RMIT website into a local SQLite database.

This documentation provides a technical overview of the projectâ€™s architecture, key methods, and libraries to help understand and maintain the system.
